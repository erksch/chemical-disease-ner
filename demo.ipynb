{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChemicalNER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erksch/chemical-disease-ner/blob/master/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpQjM1C6nuaa",
        "colab_type": "text"
      },
      "source": [
        "#Chemical Disease NER\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoeeEUUrQGQ4",
        "colab_type": "text"
      },
      "source": [
        "This notebook provides a Named Entity Recognizer for the BioCreative V challenge dataset. We will describe our implementation of data loading, processing, the use of embeddings, our model architecture and the training process briefly, with more details provided in our paper.\n",
        "\n",
        "For our model we use a bidirectional LSTM, evaluations on additional char input, the use of pretrained embeddings an more is explained in the paper.\n",
        "The implementation in this notebook resembels the baseline implementation mentioned in the paper.\n",
        "\n",
        "Our full implementation as well as our paper can be found on [Github](https://https://github.com/erksch/chemical-disease-ner) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZDsMykUn1Ul",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading and Processing\n",
        "\n",
        "The dataset is provided in XML format. The following code provides a data parser extracting the tokens from the XML format and converting it in a format fit for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x39NuA38D-mD",
        "colab_type": "text"
      },
      "source": [
        "Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ub3NueELvzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "a69c6e9a-3adb-4084-a446-fa54bdb5d875"
      },
      "source": [
        "!wget https://chemicalnerdata.s3.amazonaws.com/CDR_TrainingSet.BioC.xml\n",
        "!wget https://chemicalnerdata.s3.amazonaws.com/CDR_DevelopmentSet.BioC.xml\n",
        "!wget https://chemicalnerdata.s3.amazonaws.com/CDR_TestSet.BioC.xml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-28 11:31:32--  https://chemicalnerdata.s3.amazonaws.com/CDR_TrainingSet.BioC.xml\n",
            "Resolving chemicalnerdata.s3.amazonaws.com (chemicalnerdata.s3.amazonaws.com)... 52.216.79.36\n",
            "Connecting to chemicalnerdata.s3.amazonaws.com (chemicalnerdata.s3.amazonaws.com)|52.216.79.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2519542 (2.4M) [text/xml]\n",
            "Saving to: ‘CDR_TrainingSet.BioC.xml’\n",
            "\n",
            "CDR_TrainingSet.Bio 100%[===================>]   2.40M  3.67MB/s    in 0.7s    \n",
            "\n",
            "2020-07-28 11:31:33 (3.67 MB/s) - ‘CDR_TrainingSet.BioC.xml’ saved [2519542/2519542]\n",
            "\n",
            "--2020-07-28 11:31:35--  https://chemicalnerdata.s3.amazonaws.com/CDR_DevelopmentSet.BioC.xml\n",
            "Resolving chemicalnerdata.s3.amazonaws.com (chemicalnerdata.s3.amazonaws.com)... 52.216.82.208\n",
            "Connecting to chemicalnerdata.s3.amazonaws.com (chemicalnerdata.s3.amazonaws.com)|52.216.82.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2538784 (2.4M) [text/xml]\n",
            "Saving to: ‘CDR_DevelopmentSet.BioC.xml’\n",
            "\n",
            "CDR_DevelopmentSet. 100%[===================>]   2.42M  3.53MB/s    in 0.7s    \n",
            "\n",
            "2020-07-28 11:31:36 (3.53 MB/s) - ‘CDR_DevelopmentSet.BioC.xml’ saved [2538784/2538784]\n",
            "\n",
            "--2020-07-28 11:31:37--  https://chemicalnerdata.s3.amazonaws.com/CDR_TestSet.BioC.xml\n",
            "Resolving chemicalnerdata.s3.amazonaws.com (chemicalnerdata.s3.amazonaws.com)... 52.217.17.108\n",
            "Connecting to chemicalnerdata.s3.amazonaws.com (chemicalnerdata.s3.amazonaws.com)|52.217.17.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2595249 (2.5M) [text/xml]\n",
            "Saving to: ‘CDR_TestSet.BioC.xml’\n",
            "\n",
            "CDR_TestSet.BioC.xm 100%[===================>]   2.47M  3.80MB/s    in 0.7s    \n",
            "\n",
            "2020-07-28 11:31:38 (3.80 MB/s) - ‘CDR_TestSet.BioC.xml’ saved [2595249/2595249]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rarP679kPlN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a0ba26c1-9029-4e83-9ece-05899885f4a8"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import gensim\n",
        "from xml.dom import minidom\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJAVXG0XpFBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_dataset_xml(file_path):\n",
        "    xml = minidom.parse(file_path)\n",
        "    documents = xml.getElementsByTagName('document')\n",
        "    all_sentences = []\n",
        "    \n",
        "    for document in documents:\n",
        "        text = \"\"\n",
        "        passages = document.getElementsByTagName('passage')\n",
        "        assert(len(passages) == 2)\n",
        "        title, abstract = passages\n",
        "        text += get_text(title.getElementsByTagName('text')[0])\n",
        "        text += ' '\n",
        "        text += get_text(abstract.getElementsByTagName('text')[0])\n",
        "        annotations = document.getElementsByTagName('annotation')\n",
        "        sentences = sent_tokenize(text)\n",
        "        tokens = [word_tokenize(sentence) for sentence in sentences]\n",
        "        \n",
        "        labels = []\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            entity = get_text(annotation.getElementsByTagName('infon')[0])\n",
        "            location = annotation.getElementsByTagName('location')[0]\n",
        "            offset = int(location.attributes['offset'].value)\n",
        "            length = int(location.attributes['length'].value)\n",
        "            labels.append([text[offset:offset+length], entity])\n",
        "\n",
        "\n",
        "        flat_labels = []\n",
        "\n",
        "        for label_text, label in labels:\n",
        "            label_tokens = word_tokenize(label_text)\n",
        "            for token in label_tokens:\n",
        "                flat_labels.append([token, label])\n",
        "\n",
        "        labels = flat_labels\n",
        "\n",
        "        token_labels = []\n",
        "        label_idx = 0\n",
        "        label_start = 0\n",
        "        \n",
        "        for sentence in tokens:\n",
        "            out = []\n",
        "            \n",
        "            for token in sentence:\n",
        "                if label_idx == len(labels):\n",
        "                    out.append([token, 'O'])\n",
        "                    continue\n",
        "                    \n",
        "                text, entity = labels[label_idx]\n",
        "                text = text[label_start:]\n",
        "                \n",
        "                if token == text:\n",
        "                    label_idx += 1\n",
        "                    out.append([token, entity])\n",
        "                    label_start = 0\n",
        "                elif text.startswith(token):\n",
        "                    label_start += len(token)\n",
        "                    out.append([token, entity])\n",
        "                elif text in token:\n",
        "                    label_idx += 1\n",
        "                    out.append([token, entity])\n",
        "                else:\n",
        "                    out.append([token, 'O'])\n",
        "                    label_start = 0\n",
        "            \n",
        "            token_labels.append(out)\n",
        "\n",
        "        for sentence in token_labels:\n",
        "            all_sentences.append(sentence)\n",
        "\n",
        "    return all_sentences\n",
        "\n",
        "def get_text(node):\n",
        "    return node.childNodes[0].data\n",
        "\n",
        "def text_to_indices(sentences, word2Idx, label2Idx):\n",
        "    unknown_idx = word2Idx['UNKNOWN_TOKEN']\n",
        "    padding_idx = word2Idx['PADDING_TOKEN']\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    null_label = 'O'\n",
        "\n",
        "    for sentence in sentences:\n",
        "        word_indices = []\n",
        "        label_indices = []\n",
        "\n",
        "        for word, label in sentence:\n",
        "            if word in word2Idx:\n",
        "                wordIdx = word2Idx[word]\n",
        "            elif word.lower() in word2Idx:\n",
        "                wordIdx = word2Idx[word.lower()]\n",
        "            else:\n",
        "                wordIdx = unknown_idx\n",
        "            word_indices.append(wordIdx)\n",
        "            label_indices.append(label2Idx[label])\n",
        "\n",
        "        X.append(word_indices)\n",
        "        Y.append(label_indices)\n",
        "\n",
        "    return X, Y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BKaC8ZoPVkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_path = \"CDR_TrainingSet.BioC.xml\"\n",
        "test_set_path = \"CDR_TestSet.BioC.xml\"\n",
        "train_sentences = process_dataset_xml(training_set_path)\n",
        "test_sentences = process_dataset_xml(test_set_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU5kkIcQPgwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, Sampler\n",
        "\n",
        "class CDRDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X, Y, word2Idx, label2Idx, pad_sentences=True, pad_sentences_max_length=-1):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.word2Idx = word2Idx\n",
        "        self.label2Idx = label2Idx\n",
        "        self.max_length = pad_sentences_max_length\n",
        "        \n",
        "        if pad_sentences:\n",
        "            self._pad_sentences()\n",
        "        \n",
        "    def _pad_sentences(self):\n",
        "        pad_token = self.word2Idx['PADDING_TOKEN']\n",
        "        pad_label = self.label2Idx['O']\n",
        "\n",
        "        if self.max_length == -1:\n",
        "            for sentence in self.X:\n",
        "                self.max_length = max(self.max_length, len(sentence))\n",
        "\n",
        "        print(f\"Padding sentences to length {self.max_length} with padding token {pad_token}.\")\n",
        "\n",
        "        for i, sentence in enumerate(self.X):\n",
        "            if len(sentence) > self.max_length:\n",
        "                self.X[i] = self.X[i][:self.max_length]\n",
        "                self.Y[i] = self.Y[i][:self.max_length]\n",
        "\n",
        "            while len(sentence) < self.max_length:\n",
        "                self.X[i].append(pad_token)\n",
        "                self.Y[i].append(pad_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.LongTensor(self.X[idx]).to('cuda'), torch.LongTensor(self.Y[idx]).to('cuda')\n",
        "\n",
        "class UniqueSentenceLengthSampler(Sampler):\n",
        "    \n",
        "    def __init__(self, data_source):\n",
        "        self.data_source = data_source\n",
        "        self.sentence_lengths = set()\n",
        "\n",
        "        for x, _ in data_source:\n",
        "            self.sentence_lengths.add(len(x))\n",
        "\n",
        "    def __iter__(self):\n",
        "        batch = []\n",
        "        for sentence_length in self.sentence_lengths:\n",
        "            for idx in range(len(self.data_source)):\n",
        "                x, _ = self.data_source[idx]\n",
        "                if (len(x) == sentence_length):\n",
        "                    batch.append(idx)\n",
        "            yield batch\n",
        "            batch = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_source)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ20hpwnQtg9",
        "colab_type": "text"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "For this example we use our own embeddings. We also experimented with pretrained embeddings, more on that in our paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoKhvChaRFx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_words_and_labels(sentences):\n",
        "    labels = set()\n",
        "    words = set()\n",
        "\n",
        "    print(\"Extracting words and labels...\")\n",
        "    for sentence in sentences:\n",
        "        for token, label in sentence:\n",
        "            labels.add(label)\n",
        "            words.add(token.lower())\n",
        "    print(f\"Extracted {len(words)} words and {len(labels)} labels.\")\n",
        "\n",
        "    return words, labels\n",
        "    \n",
        "def prepare_indices(sentences):\n",
        "    words, labels = extract_words_and_labels(sentences)\n",
        "\n",
        "    # mapping for words\n",
        "    word2Idx = {}\n",
        "    word2Idx[\"PADDING_TOKEN\"] = 0\n",
        "    word2Idx[\"UNKNOWN_TOKEN\"] = 1\n",
        "\n",
        "    for word in words:\n",
        "        word2Idx[word] = len(word2Idx)\n",
        "\n",
        "    # mapping for labels\n",
        "    label2Idx = {}\n",
        "    for label in labels:\n",
        "        label2Idx[label] = len(label2Idx)\n",
        "    \n",
        "    idx2Label = {v: k for k, v in label2Idx.items()}\n",
        "\n",
        "    return word2Idx, label2Idx, idx2Label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGzcj-zUQ9-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "37706791-ac5d-4579-9e6a-be27ef467ed7"
      },
      "source": [
        "word2Idx, label2Idx, idx2Label = prepare_indices(train_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting words and labels...\n",
            "Extracted 10400 words and 3 labels.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZlPLkzYRWkR",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "Our model is a bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8Hkrr7xRYxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, embedding_dim, hidden_dim, dropout, vocab_size, num_classes):\n",
        "        super(BiLSTM, self).__init__()\n",
        "  \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim, bidirectional=True)\n",
        "        self.linear = nn.Linear(self.hidden_dim* 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6dq67eNSrRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim=200 \n",
        "hidden_dim=200\n",
        "dropout=0.5\n",
        "model_args = {}\n",
        "vocab_size = len(word2Idx)\n",
        "num_classes = len(label2Idx)\n",
        "device = torch.device('cuda')\n",
        "f1_scores = {label: 0.0 for label in idx2Label.keys()}\n",
        "\n",
        "model = BiLSTM(embedding_dim=embedding_dim, hidden_dim=hidden_dim, dropout=dropout, vocab_size=vocab_size, num_classes=num_classes, **model_args).to(device)\n",
        "\n",
        "X_train, Y_train = text_to_indices(train_sentences, word2Idx, label2Idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyUrdQjBS43F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3c47dd9a-da44-4e9e-f399-2566c98367b5"
      },
      "source": [
        "print(\"Train dataset class distribution:\")\n",
        "total = len([token for sentence in Y_train for token in sentence])\n",
        "non_null_class_weight = 1.0\n",
        "null_class_weight = 0.1\n",
        "weights = []\n",
        "print(f\"Total of {total} tokens\")\n",
        "for i, label in enumerate(label2Idx):\n",
        "    count = 0\n",
        "    for sentence in Y_train:\n",
        "        count += len(np.where(np.array(sentence) == label2Idx[label])[0])\n",
        "    end = ' | ' if i < len(label2Idx) -1 else ''\n",
        "    print(f\"{label} {count} {count / total:.2f}\", end=end)\n",
        "\n",
        "    weight = non_null_class_weight if (count / total) < 0.1 else null_class_weight\n",
        "    weights.append(weight)\n",
        "print()\n",
        "print(f\"Weights: {weights}\")\n",
        "\n",
        "X_test, Y_test = text_to_indices(test_sentences, word2Idx, label2Idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset class distribution:\n",
            "Total of 107488 tokens\n",
            "Chemical 1664 0.02 | O 104031 0.97 | Disease 1793 0.02\n",
            "Weights: [1.0, 0.1, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm6uP8ZqUIom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1536e533-08ce-4335-c3df-6e88447e98d8"
      },
      "source": [
        "dataset_args = {}\n",
        "dataset = CDRDataset(X_train, Y_train, word2Idx, label2Idx, **dataset_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padding sentences to length 111 with padding token 0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFv2ui7JXeJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNn1jhvRXtdR",
        "colab_type": "text"
      },
      "source": [
        "##  Batching\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBfQpLtuXwu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# single, padded_sentences, by_sentence_length\n",
        "batch_mode=\"single\"\n",
        "padded_sentences_batch_size=100\n",
        "# set to -1 to use max sentence length of train set\n",
        "padded_sentences_max_length=20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UnIq0PPXzTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUvz5yZ6Yb8C",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9xchi7_X6mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate=0.001\n",
        "sgd_momentum=0.9\n",
        "epochs=10\n",
        "\n",
        "loss_args = { \"weight\": torch.FloatTensor(weights).to(device) }\n",
        "criterion = nn.CrossEntropyLoss(**loss_args)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JiU63jpaFKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_dataset(X, Y, net):\n",
        "    all_true_labels = []\n",
        "    all_predicted_labels = []\n",
        "\n",
        "    for i, x in enumerate(X):\n",
        "        tokens = torch.LongTensor([x]).to(device)\n",
        "        true_labels = torch.LongTensor(Y[i]).to(device)\n",
        "\n",
        "        predicted_labels = net(tokens)\n",
        "        predicted_labels = predicted_labels.argmax(axis=2).squeeze(dim=0)\n",
        "\n",
        "        for j in range(len(true_labels)):\n",
        "            all_true_labels.append(true_labels[j].item())\n",
        "            all_predicted_labels.append(predicted_labels[j].item())\n",
        "\n",
        "    return torch.LongTensor(all_true_labels), torch.LongTensor(all_predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YqxqHAIYJFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "16a901bc-42c0-415b-b075-4fb11d6e1ff5"
      },
      "source": [
        "print(\"Training...\")\n",
        "n_iter = 0\n",
        "for epoch in range(epochs):\n",
        "    epoch_start = time.time()\n",
        "    model.train()\n",
        "\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        prediction = model(batch_x).reshape(-1, num_classes)\n",
        "        loss = criterion(prediction, batch_y.reshape(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        n_iter += 1\n",
        "\n",
        "    epoch_end = time.time()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} | Loss {loss.item():.2f} | Duration {(epoch_end - epoch_start):.2f}s\")\n",
        "\n",
        "    should_evaluate = (epoch + 1) == epochs or epoch % 5 == 0 # only evaluate every 5th epoch for performance\n",
        "\n",
        "    if should_evaluate:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            eval_total_start = time.time()\n",
        "\n",
        "            for set_name,X, Y in [('train',X_train, Y_train), ('test', X_test, Y_test)]:\n",
        "                eval_set_start = time.time()\n",
        "                ground_truth, predictions = predict_dataset(X, Y, model)\n",
        "                true_positives = (ground_truth == predictions).sum().item()\n",
        "                accuracy = true_positives / len(ground_truth)\n",
        "                \n",
        "                print(f\"{set_name} set evaluation:\")\n",
        "                \n",
        "                for label in idx2Label.keys():\n",
        "                    indices_in_class = torch.where(ground_truth == label)[0]\n",
        "                    true_positives = (ground_truth[indices_in_class] == predictions[indices_in_class]).sum().item()\n",
        "                    false_negatives = len(indices_in_class) - true_positives\n",
        "            \n",
        "                    recall = true_positives / len(indices_in_class)\n",
        "\n",
        "                    indices_predicted_in_class = torch.where(predictions == label)[0]\n",
        "                    false_positives = (ground_truth[indices_predicted_in_class] != predictions[indices_predicted_in_class]).sum().item()\n",
        "\n",
        "                    if true_positives + false_positives == 0:\n",
        "                        precision = 0\n",
        "                    else:\n",
        "                        precision = true_positives / (true_positives + false_positives)\n",
        "\n",
        "                    f1_score = (2 * true_positives) / (2 * true_positives + false_positives + false_negatives)\n",
        "                    f1_scores[label] = f1_score\n",
        "\n",
        "                    print(f\"\\t{idx2Label[label]:<8} | P {precision:.2f} | R {recall:.2f} | F1 {f1_score:.2f}\")\n",
        "\n",
        "                eval_set_end = time.time()\n",
        "                print(f\"\\tTook {(eval_set_end - eval_set_start):.2f}s\")\n",
        "\n",
        "            eval_total_end = time.time()\n",
        "            print(f\"\\Total evaluation duration {(eval_total_end - eval_total_start):.2f}s\")\n",
        "\n",
        "f1_mean = (f1_scores[label2Idx['Disease']] + f1_scores[label2Idx['Chemical']]) / 2\n",
        "print(f\"Mean f1 score: {f1_mean}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch 1 | Loss 0.10 | Duration 14.36s\n",
            "train set evaluation:\n",
            "\tChemical | P 0.45 | R 0.92 | F1 0.60\n",
            "\tO        | P 1.00 | R 0.99 | F1 1.00\n",
            "\tDisease  | P 0.36 | R 0.84 | F1 0.51\n",
            "\tTook 18.91s\n",
            "test set evaluation:\n",
            "\tChemical | P 0.30 | R 0.40 | F1 0.34\n",
            "\tO        | P 0.98 | R 0.96 | F1 0.97\n",
            "\tDisease  | P 0.26 | R 0.55 | F1 0.35\n",
            "\tTook 6.11s\n",
            "\\Total evaluation duration 25.02s\n",
            "Epoch 2 | Loss 0.01 | Duration 14.21s\n",
            "Epoch 3 | Loss 0.03 | Duration 14.16s\n",
            "Epoch 4 | Loss 0.01 | Duration 14.44s\n",
            "Epoch 5 | Loss 0.02 | Duration 14.46s\n",
            "Epoch 6 | Loss 0.03 | Duration 14.18s\n",
            "train set evaluation:\n",
            "\tChemical | P 0.48 | R 0.89 | F1 0.62\n",
            "\tO        | P 1.00 | R 0.99 | F1 1.00\n",
            "\tDisease  | P 0.35 | R 0.87 | F1 0.49\n",
            "\tTook 18.81s\n",
            "test set evaluation:\n",
            "\tChemical | P 0.31 | R 0.36 | F1 0.33\n",
            "\tO        | P 0.98 | R 0.96 | F1 0.97\n",
            "\tDisease  | P 0.24 | R 0.57 | F1 0.34\n",
            "\tTook 6.20s\n",
            "\\Total evaluation duration 25.01s\n",
            "Epoch 7 | Loss 0.01 | Duration 14.02s\n",
            "Epoch 8 | Loss 0.40 | Duration 14.15s\n",
            "Epoch 9 | Loss 0.06 | Duration 14.21s\n",
            "Epoch 10 | Loss 0.03 | Duration 14.14s\n",
            "train set evaluation:\n",
            "\tChemical | P 0.50 | R 0.88 | F1 0.63\n",
            "\tO        | P 1.00 | R 0.99 | F1 1.00\n",
            "\tDisease  | P 0.36 | R 0.85 | F1 0.50\n",
            "\tTook 18.84s\n",
            "test set evaluation:\n",
            "\tChemical | P 0.33 | R 0.35 | F1 0.34\n",
            "\tO        | P 0.98 | R 0.96 | F1 0.97\n",
            "\tDisease  | P 0.25 | R 0.55 | F1 0.34\n",
            "\tTook 6.06s\n",
            "\\Total evaluation duration 24.90s\n",
            "Mean f1 score: 0.3418590724136922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yCUrMuRY3_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}